[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "pacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse)\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nBeyond ggplot2 Annotation:ggrepel\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n             fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: ggrepel: 317 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x=MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_grey()+\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x=MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_economist()+\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x=MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_ipsum()+\n  ggtitle(\"Distribution of Maths scores\")\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x=MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_ipsum(axis_text_size = 18,\n              base_size = 15,\n    grid = \"Y\")+\n  ggtitle(\"Distribution of Maths scores\")\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x=MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_grey()+\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x=ENGLISH))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_grey()+\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,\n           y=ENGLISH))+\n  geom_point()+\n  geom_smooth(method = lm, size = 0.5)+\n  coord_cartesian(xlim=c(0,100),\n                  ylim = c(0,100))+\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\np1 <- ggplot(data = exam_data,\n       aes(x=MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_grey()+\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 <- ggplot(data = exam_data,\n       aes(x=ENGLISH))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_grey()+\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np1 + p2\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,\n           y=ENGLISH))+\n  geom_point()+\n  geom_smooth(method = lm, size = 0.5)+\n  coord_cartesian(xlim=c(0,100),\n                  ylim = c(0,100))+\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\np1 <- ggplot(data = exam_data,\n       aes(x=MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_grey()+\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 <- ggplot(data = exam_data,\n       aes(x=ENGLISH))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_grey()+\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3 <- ggplot(data=exam_data,\n       aes(x=MATHS,\n           y=ENGLISH))+\n  geom_point()+\n  geom_smooth(method = lm, size = 0.5)+\n  coord_cartesian(xlim=c(0,100),\n                  ylim = c(0,100))+\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n(p1 /p2) |p3\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\np1 <- ggplot(data = exam_data,\n       aes(x=MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_grey()+\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 <- ggplot(data = exam_data,\n       aes(x=ENGLISH))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_grey()+\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3 <- ggplot(data=exam_data,\n       aes(x=MATHS,\n           y=ENGLISH))+\n  geom_point()+\n  geom_smooth(method = lm, size = 0.5)+\n  coord_cartesian(xlim=c(0,100),\n                  ylim = c(0,100))+\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\np1 <- ggplot(data = exam_data,\n       aes(x=ENGLISH))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_grey()+\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np2 <- ggplot(data=exam_data,\n       aes(x=MATHS,\n           y=ENGLISH))+\n  geom_point()+\n  geom_smooth(method = lm, size = 0.5)+\n  coord_cartesian(xlim=c(0,100),\n                  ylim = c(0,100))+\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\np2 + inset_element(p1,\n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\np1 <- ggplot(data = exam_data,\n       aes(x=MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_grey()+\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 <- ggplot(data = exam_data,\n       aes(x=ENGLISH))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 fill = \"grey90\",\n                 color = \"black\")+\n  theme_grey()+\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3 <- ggplot(data=exam_data,\n       aes(x=MATHS,\n           y=ENGLISH))+\n  geom_point()+\n  geom_smooth(method = lm, size = 0.5)+\n  coord_cartesian(xlim=c(0,100),\n                  ylim = c(0,100))+\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\npatchwork <- (p1 /p2) |p3\npatchwork & theme_economist()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "pacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "Install packages\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\nData Import\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nVisualising Distribution with Ridgeline Plot: ggridges method\n\nThe plotThe code chunk\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nVisualising Distribution with Ridgeline Plot: Varying fill colors along the x axis\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\nWarning: `stat(x)` was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(x)` instead.\n\n\nPicking joint bandwidth of 3.18\n\n\n\n\n\nMapping the probabilities directly onto colour\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\nPicking joint bandwidth of 3.18\n\n\n\n\n\nRidgeline plots with quantile lines\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\nPicking joint bandwidth of 3.18\n\n\nWarning: Using the `size` aesthetic with geom_segment was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\nPicking joint bandwidth of 3.18\n\n\n\n\n\nPlotting a Half Eye graph\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\nAdding the boxplot with geom_boxplot()\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\nAdding the Dot plots with stat_dots()\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\n\nRows: 54 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): label, Department, Title\ndbl (1): id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\nRows: 9063 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): SentDate, Subject, MainSubject, sourceLabel, targetLabel\ndbl  (2): source, target\ntime (1): SentTime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\nGAStech_edges <- GAStech_edges %>%\n  mutate(SendDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(source, target, Weekday) %>%\n    summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 1) %>%\n  ungroup()\n\n`summarise()` has grouped output by 'source', 'target'. You can override using\nthe `.groups` argument.\n\n\n\nGAStech_graph <- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 4\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# ℹ 48 more rows\n#\n# A tibble: 1,372 × 4\n   from    to Weekday Weight\n  <int> <int> <ord>    <int>\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\nGAStech_graph %>%\n  activate(edges) %>%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 1,372 × 4\n   from    to Weekday  Weight\n  <int> <int> <ord>     <int>\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# ℹ 1,366 more rows\n#\n# A tibble: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\nUsing \"stress\" as default layout\n\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\n\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\nUsing \"stress\" as default layout\n\ng + theme_graph()\n\n\n\n\n\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\nUsing \"stress\" as default layout\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\ng <- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\nset_graph_style() \n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\ng <- GAStech_graph %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\ng <- GAStech_graph %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\ng <- GAStech_graph %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `community = as.factor(group_edge_betweenness(weights = Weight,\n  directed = TRUE))`.\nCaused by warning in `cluster_edge_betweenness()`:\n! At core/community/edge_betweenness.c:492 : Membership vector will be selected based on the highest modularity score.\n\ng + theme_graph()\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\nBuilding Interactive Network Graph with visNetwork\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\n`summarise()` has grouped output by 'from'. You can override using the\n`.groups` argument.\n\n\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\nGAStech_nodes <- GAStech_nodes %>%\n  rename(group = Department) \n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands on Exercise 7",
    "section": "",
    "text": "pacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\n\nattacks <- read_csv(\"data/eventlog.csv\")\n\nRows: 199999 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): source_country, tz\ndttm (1): timestamp\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\n\n\n\n\n\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\n\n\n\n\n\n\n\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\n\n\n\n\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()\n\n\n\n\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-import-1",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-import-1",
    "title": "Hands on Exercise 7",
    "section": "Data Import",
    "text": "Data Import\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-preparation-2",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-preparation-2",
    "title": "Hands on Exercise 7",
    "section": "Data preparation",
    "text": "Data preparation\n\nStep 1: Derive month and year\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n\n\nStep 2: Extract target country Japan\n\nJapan <- air %>% \n  select(`Japan`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n\n\nStep 3: Compute year average arrivals by month\n\nhline.data <- Japan %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Japan`))\n\n\n\nStep 4: Plotting the cycle plot\n\nggplot() + \n  geom_line(data=Japan,\n            aes(x=year, \n                y=`Japan`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Japan by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-import-2",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-import-2",
    "title": "Hands on Exercise 7",
    "section": "Data Import",
    "text": "Data Import\n\nrice <- read_csv(\"data/rice.csv\")\n\nRows: 550 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Country\ndbl (3): Year, Yield, Production\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-the-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-the-slopegraph",
    "title": "Hands on Exercise 7",
    "section": "Plotting the slopegraph",
    "text": "Plotting the slopegraph\n\nrice %>% \n  mutate(Year = factor(Year)) %>%\n  filter(Year %in% c(1961, 1980)) %>%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Fang Zi Wei\")\n\n\nConverting 'Year' to an ordered factor"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#load-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#load-packages-1",
    "title": "Hands on Exercise 7",
    "section": "Load packages",
    "text": "Load packages\n\npacman::p_load(ggHoriPlot, ggthemes, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-import-3",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-import-3",
    "title": "Hands on Exercise 7",
    "section": "Data Import",
    "text": "Data Import\n\naverp <- read_csv(\"data/AVERP.csv\") %>%\n  mutate(`Date` = dmy(`Date`))\n\nRows: 7452 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Date, Consumer Items\ndbl (1): Values\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-the-horizon-graph",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-the-horizon-graph",
    "title": "Hands on Exercise 7",
    "section": "Plotting the horizon graph",
    "text": "Plotting the horizon graph\n\naverp %>% \n  filter(Date >= \"2018-01-01\") %>%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer Items`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands on exercise 8",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)\n\n\n\n\nmpsz <- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zwfang315\\ISSS608-VAA-2\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#load-packages",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#load-packages",
    "title": "Hands on exercise 8",
    "section": "Load Packages",
    "text": "Load Packages\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#import-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#import-data",
    "title": "Hands on exercise 8",
    "section": "Import Data",
    "text": "Import Data\n\nsgpools <- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nRows: 306 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): NAME, ADDRESS, OUTLET TYPE\ndbl (4): POSTCODE, XCOORD, YCOORD, Gp1Gp2 Winnings\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   <chr>          <chr>      <dbl>  <dbl>  <dbl> <chr>                     <dbl>\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "title": "Hands on exercise 8",
    "section": "Creating a sf data frame from an aspatial data frame",
    "text": "Creating a sf data frame from an aspatial data frame\n\nsgpools_sf <- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * <chr>                        <chr>      <dbl> <chr>                     <dbl>\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry <POINT [m]>"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-proportional-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-proportional-symbol-map",
    "title": "Hands on exercise 8",
    "section": "Drawing Proportional Symbol Map",
    "text": "Drawing Proportional Symbol Map\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\n\nIt all started with an interactive point symbol map\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nLets make it proportional\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\nLegend for symbol sizes not available in view mode.\n\n\n\n\n\n\n\n\n\nLets give it a different colour\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\nLegend for symbol sizes not available in view mode.\n\n\n\n\n\n\n\n\n\nTwin tmaps\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\nLegend for symbol sizes not available in view mode.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class_Ex01",
    "section": "",
    "text": "Getting started\n\npacman::p_load(tidyverse)\n\nImporting data\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nggplot(data = exam_data,\n       aes(y=RACE))+\n  geom_bar()+\n  theme_minimal()+\n  theme(\n    panel.background = element_rect(fill = \"light blue\", color = \"light blue\", size = 0.5, linetype = \"solid\"),\n    panel.grid.major = element_line(size = 0.5, linetype = 'solid', colour = \"white\"), \n    panel.grid.minor = element_line(size = 0.25, linetype = 'solid', colour = \"white\"))\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar()\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = reorder(RACE,RACE,\n                function(x)-length(x))))+\n         geom_bar()+\n  geom_text(stat=\"count\",\n            aes(label = paste0(..count.., \", \",\n            round(..count../sum(..count..)*100, 1), \"%\")), vjust = -0.5)+\n  ylim(0,220)+\n  ylab(\"No. of Pupils\")+\n  xlab(\"Race\")+\n  theme(axis.title.y=element_text(angle = 0))\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\nexam_data %>%\n  mutate(RACE = fct_infreq(RACE)) %>%\n  ggplot(aes(x = RACE)) + \n  geom_bar()+\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(..count.., \", \", \n      round(..count../sum(..count..)*100,\n            1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS))+\n  geom_histogram(bins=20)\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS))+\n  geom_histogram(fill = \"light blue\",\n                 bins = 20,\n                 color = \"black\")+\n  geom_vline(aes(xintercept = mean(MATHS, na.rm = T)),\n             color = \"red\",\n             linetype = \"dashed\",\n             size = 1)+\n  geom_vline(aes(xintercept = median(MATHS, na.rm = T)),\n             color = \"dark blue\",\n             linetype = \"dashed\",\n             size = 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= ENGLISH)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ GENDER)\n\n\n\n\n\ndata <- exam_data\nd_bg <- data[,-3]\n\nggplot(data=exam_data, \n       aes(x= ENGLISH, fill = GENDER)) +\n  geom_histogram(bins=20,\n                 color = \"black\")+\n  geom_histogram(data=d_bg, fill = \"grey\", alpha = .5)+\n    facet_wrap(~ GENDER)+\n      guides(fill = FALSE)+\n  theme_bw()+\n  ylim(0,30)\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS,\n           y = ENGLISH))+\n  geom_point() +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))+\n  geom_hline(yintercept = 50,\n             linetype=\"dashed\",\n             color = \"grey60\",\n             size=1)+\n  geom_vline(xintercept = 50,\n             linetype=\"dashed\",\n             color = \"grey60\",\n             size=1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(rstatix, gt, patchwork, tidyverse)\n\n\nexam_data = read_csv(\"data/Exam_data.csv\")\n\nVisualising Normal Distribution A QQ plot, short for “quantile-quantile” plot, is used to assess whether or not a set of data potentially came from some theoretical distribution. In most cases, this type of plot is used to determine whether or not a set of data follows a normal distribution.\nif the data is normally distributed the points in a QQ plot will like on a straight diagonal line. Conversely, if the points deviate significantly from the straight diagonal line, then it’s less likely that the data is normally distributed.\nstat_qq_line() provide the line stat_qq() provide the dots echo:false will only plot out the graph eval: false will only show the code chunk\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam_data,\n       aes(sample = ENGLISH)) +\n  stat_qq() +\n  stat_qq_line()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can see that the points deviate significantly from the straight diagonal line. This is a clear indication that the set of data is not normally distributed.\n\n\nCombining statistical graph and analysis table\nNeed to install webshot\n:::panel-tabset"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class_Ex05",
    "section": "",
    "text": "tbl_graph convert table into graph object\nonce has the model from tbl_graph, use ggraph to visualise THE GRAPH is messy, use differnt layout to make visualiziation easy\nlayout： force-directed (push nodes as far as possible, but still)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html",
    "title": "Exploring City of Engagement’s household demographic and spending patterns",
    "section": "",
    "text": "The City of Engagement is utilizing the survey data to shape its community revitalization plans, specifically with the aim of maximizing the impact of a recently acquired substantial city renewal grant.\n\n\nTo help the city effectively allocate resources towards significant community development initiatives, we need to offer valuable insights into household demographics and hidden patterns by analyzing survey data.\n\n\n\n\npacman::p_load(ggstatsplot, ggthemes, plotly, corrplot, lubridate, ggpubr, plotly, treemap, hrbrthemes, ggrepel, RColorBrewer, gganimate, viridis, ggridges, ggrepel, testthat, hmisc, tidyverse, skimr, DT, ggiraph, ggplot2, dplyr, broom)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#data-preparation---financial-journal",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#data-preparation---financial-journal",
    "title": "Exploring City of Engagement’s household demographic and spending patterns",
    "section": "Data Preparation - Financial journal",
    "text": "Data Preparation - Financial journal\nPrior to conducting data analysis and visualization, it is crucial to engage in data preparation procedures to guarantee the cleanliness, organization, and suitability of the data for analysis purposes. Presented below are data preparation steps.\n\nStep 1: Sort the data by participantId\n\n\nShow code\n##sort the dataset by participantid\nfinancialjournal <- financialjournal[order(financialjournal$participantId),]\n\n\n\n\nStep 2: Check missing values\n\n##check missing values\ncolSums(is.na(financialjournal))\n\nparticipantId     timestamp      category        amount \n            0             0             0             0 \n\n\n\n\nStep 3: Check any duplicates records\n1113 rows of duplicates were found.\n\n##check for duplicates\ndup_rows <- duplicated(financialjournal)\nfinancialjournal[dup_rows, ]\n\n# A tibble: 1,113 × 4\n   participantId timestamp           category   amount\n           <dbl> <dttm>              <chr>       <dbl>\n 1             0 2022-03-01 00:00:00 Shelter    -555. \n 2             0 2022-03-01 00:00:00 Education   -38.0\n 3             1 2022-03-01 00:00:00 Shelter    -555. \n 4             1 2022-03-01 00:00:00 Education   -38.0\n 5             2 2022-03-01 00:00:00 Shelter    -557. \n 6             2 2022-03-01 00:00:00 Education   -12.8\n 7             3 2022-03-01 00:00:00 Shelter    -555. \n 8             3 2022-03-01 00:00:00 Education   -38.0\n 9             4 2022-03-01 00:00:00 Shelter   -1556. \n10             4 2022-03-01 00:00:00 Education   -12.8\n# ℹ 1,103 more rows\n\n\n\n\nStep 4: Remove duplicates\nAfter removing duplicates, the dataset now comprises 1010 unique participants with a total of 1512523 records.\n\n\nShow code\n##remove duplicates\nfinancialjournal_distinct <- unique(financialjournal)\n\n\n\n\nStep 5: Transform Time into Year, Month\n\n\nShow code\n##Split the timestamp into date and time\nfinancialjournal_distinct[c('Date', 'Time')] <- str_split_fixed(financialjournal_distinct$timestamp, ' ', 2)\n\nfinancialjournal_distinct[c('Year', 'Month', 'Day')] <- str_split_fixed(financialjournal_distinct$Date, '-', 3)\n\n##Drop timestamp, time and day of the date\nfinancialjournal_distinct <- subset(financialjournal_distinct, select = -c(Time, timestamp, Day))\n\n\n\n\nStep 6: Data aggregation on amount by year and month\n\n\nShow code\ndf <- financialjournal_distinct\n\naggregated <- aggregate(amount ~ participantId + category + Year + Month, data = df, FUN =sum)\n\naggregated <- aggregated[order(aggregated$participantId,aggregated$category, aggregated$Year,aggregated$Month),]\n\n\n\n\nStep 7: Pivot table - one participant one record\n\n\nShow code\npivot_table <- pivot_wider(aggregated, names_from = category, values_from = amount, values_fill = 0)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#data-preparation---participants",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#data-preparation---participants",
    "title": "Exploring City of Engagement’s household demographic and spending patterns",
    "section": "Data preparation - Participants",
    "text": "Data preparation - Participants\n\nCheck missing values\n\ncolSums(is.na(participants))\n\n participantId  householdSize       haveKids            age educationLevel \n             0              0              0              0              0 \n interestGroup      joviality \n             0              0 \n\n\n\n\nMerge two tables by participantId\n\nmerged_table <- merge(pivot_table, participants, by = \"participantId\")\n\n\nglimpse(merged_table,30)\n\nRows: 10,691\nColumns: 15\n$ participantId  <dbl> 0, 0,…\n$ Year           <chr> \"2022…\n$ Month          <chr> \"03\",…\n$ Education      <dbl> -38.0…\n$ Food           <dbl> -268.…\n$ Recreation     <dbl> -348.…\n$ Shelter        <dbl> -554.…\n$ Wage           <dbl> 11931…\n$ RentAdjustment <dbl> 0, 0,…\n$ householdSize  <dbl> 3, 3,…\n$ haveKids       <lgl> TRUE,…\n$ age            <dbl> 36, 3…\n$ educationLevel <chr> \"High…\n$ interestGroup  <chr> \"H\", …\n$ joviality      <dbl> 0.001…\n\n\n\n\nChange Data Type\nparticipantId, year and month should treat as character\n\n\nShow code\nmerged_table$participantId <- as.character(merged_table$participantId)\nmerged_table$Year <- as.character(merged_table$Year)\nmerged_table$Month <- as.character(merged_table$Month)\n\n\n\n\nCreate new variables and grouping\n\nNew variables: “Savings”, “Total Expense” and “Date”\nTo see if we get catch any additional information or pattern in the dataset, we will create two new variables:\nSavings = Wage + Shelter + Education + Food + Recreation + RentAdjustment Total_Expense = Shelter + Education + Food + Recreation + RentAdjustment Date: “Year”-“Month” (e.g. 2022-03)\n\n\nShow code\nmerged_table <- merged_table %>% \n  mutate(Savings = Wage + Shelter + Education + Food + Recreation + RentAdjustment, Total_Expense = Shelter + Education + Food + Recreation + RentAdjustment)\n\nmerged_table$Date <- paste0(merged_table$Year, \"-\",merged_table$Month)\n\n\n\n\nNew grouping: age_group, wage_group, savings_group\nTo explore patterns, trends or relationships across different group more easily. We create following three groupings: age_group: break into 6 groups. 18-25, 25-32, 32-39, 39-46, 46-53, 53-60 wage_group: break into 5 groups. Super low, low, medium, high, super high savings_group: break into 5 groups. Super low, low, medium, high, super high\n\n\nShow code\nage_ranges <- c(18, 25, 32, 39, 46, 53,60)\nlabels <- paste(age_ranges[-length(age_ranges)], age_ranges[-1], sep = \"-\")\nmerged_table$age_group <- cut(merged_table$age, breaks = age_ranges, include.lowest = TRUE,labels = labels)\nwage_ranges <- c(1600.00, 5546.93, 9493.86, 13440.79, 17387.72, 21334.65)\ngroup_names <- c(\"super low\", \"low\", \"medium\", \"high\", \"super high\")\nmerged_table$wage_group <- cut(merged_table$Wage, breaks = wage_ranges, include.lowest = TRUE, labels = group_names)\nsavings_ranges <- c(-362.7011,3672.3091,7707.3193,11742.3296,15777.3398,19812.3500)\nmerged_table$savings_group <- cut(merged_table$Savings, breaks = savings_ranges, include.lowest = TRUE, labels = group_names)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#wage-vs.-education-level",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#wage-vs.-education-level",
    "title": "Exploring City of Engagement’s household demographic and spending patterns",
    "section": "Wage vs. Education level",
    "text": "Wage vs. Education level\nThe distribution across education levels are all right-skewed. ::: panel-tabset ## The plot"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#code-2",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#code-2",
    "title": "Exploring City of Engagement’s household demographic and spending patterns",
    "section": "Code",
    "text": "Code\n\nsummary_merged_table <- merged_table %>%\n  group_by(educationLevel) %>%\n  summarise(mean_wage = mean(Wage), sd_wage = sd(Wage))\n\nggplot(merged_table, aes(x = Wage)) +\n  geom_histogram(aes(y=..density..), binwidth = 500, color = \"grey25\", fill=\"grey90\") +\n  scale_y_continuous(labels = function(x) paste0(x*1000, \"k\")) +\n  labs(x = \"Wage\", y = \"Count\")+\n  ggtitle(\"Histogram of wage by Education Level\")+\n  geom_vline(data = summary_merged_table, aes(xintercept = mean_wage),\n             linetype = \"dashed\", size = 1) +\n  facet_wrap(~ educationLevel, ncol = 2)+\n  theme_minimal()\n\n:::\nNormal QQ plot is used to verify whether wage follows normal distribution among different education level.\nOut of 4 QQ plots, the tails of the distribution start deviating from the normal distribution line, which suggests that there are outliers or extreme values in each education level.\n\nLowHighSchoolOrCollegeBachelorGraduateCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Subset the data for a specific education level\nsubset_data_bachelor <- subset(merged_table, educationLevel == \"Bachelors\")\n\n# Check if the subsetted data contains valid values\nif (any(is.na(subset_data_bachelor$Wage)) || nrow(subset_data_bachelor) == 0) {\n  print(\"Subsetted data is empty or contains missing values.\")\n} else {\n  # Create the QQ plot of savings for the subsetted data\n  p1 <- qqnorm(subset_data_bachelor$Wage, main = \"QQ Plot of Wage - Bachelor's\")\n  qqline(subset_data_bachelor$Wage)\n}\n\n# Subset the data for a specific education level\nsubset_data_low <- subset(merged_table, educationLevel == \"Low\")\n\n# Check if the subsetted data contains valid values\nif (any(is.na(subset_data_low$Wage)) || nrow(subset_data_low) == 0) {\n  print(\"Subsetted data is empty or contains missing values.\")\n} else {\n  # Create the QQ plot of savings for the subsetted data\n  qqnorm(subset_data_low$Wage, main = \"QQ Plot of Wage - Low\")\n  qqline(subset_data_low$Wage)\n}\n\nsubset_data_graduate <- subset(merged_table, educationLevel == \"Graduate\")\n\n# Check if the subsetted data contains valid values\nif (any(is.na(subset_data_graduate$Wage)) || nrow(subset_data_graduate) == 0) {\n  print(\"Subsetted data is empty or contains missing values.\")\n} else {\n  # Create the QQ plot of savings for the subsetted data\n  qqnorm(subset_data_graduate$Wage, main = \"QQ Plot of Wage - Graduate\")\n  qqline(subset_data_graduate$Wage)\n}\n\nsubset_data_highschool <- subset(merged_table, educationLevel == \"HighSchoolOrCollege\")\n\n# Check if the subsetted data contains valid values\nif (any(is.na(subset_data_highschool$Wage)) || nrow(subset_data_highschool) == 0) {\n  print(\"Subsetted data is empty or contains missing values.\")\n} else {\n  # Create the QQ plot of savings for the subsetted data\n  qqnorm(subset_data_highschool$Wage, main = \"QQ Plot of Wage - HighSchoolOrCollege\")\n  qqline(subset_data_highschool$Wage)\n}\n\n\n\n\nSince it’s not normal distributed based on above QQ plots, we need to perform nonparametric test (Kruskal-Wallis) to perform the hypothesis testing.\nHypothesis assumptions:\nH0: there is no difference between wage across education levels\nH1: there is difference between wage across education levels\nFrom violin plot, it suggested that p-value is less than 0.05. We reject the null hypothesis, and fail to reject alternative hypothesis.\nConclusion: There is wage difference across education."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#one-way-anova-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#one-way-anova-analysis",
    "title": "Exploring City of Engagement’s household demographic and spending patterns",
    "section": "One-way ANOVA analysis",
    "text": "One-way ANOVA analysis\nTo check how much difference is it between each education level pairing, one-way anova is performed.\n\nThe plotCode\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(data = merged_table,\n               x = educationLevel, y = Wage,\n               xlab = \"Education Level\", ylab = \"Wage\",\n               type = \"np\", pairwise.comparisons = TRUE, pairwise.display = \"ns\", \n               mean.ci = TRUE, p.adjust.method = \"fdr\",\n              messages = FALSE) +\n  scale_y_continuous(limits = c(0, 15000))\n\n\n\n\nAs expected, graduate has the highest wage, followed by bachelors, highschool or college and Low. The wage difference between graduate and low is the hugest."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#tukeys-test",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#tukeys-test",
    "title": "Exploring City of Engagement’s household demographic and spending patterns",
    "section": "Tukey’s test",
    "text": "Tukey’s test\nTo determine if there are significant differences between the means of education levels after conducting an ANOVA, Tukey’s test is applied.\nIn summary, the Tukey’s test results indicate significant differences in the means between various groups. Here are the key findings:\n\n“Low” have a significantly lower mean compared to “Graduate” participants, with a mean difference of -3565.5254.\n“Graduate” have a significantly higher mean compared to “Bachelors” participants, with a mean difference of 1191.6695.\n\nThe p-values for all comparisons are reported as 0, indicating that the observed differences are statistically significant. The 95% confidence intervals for the mean differences do not include zero, further supporting the significant differences between the groups.\n\nTukeyHSD ResultCode\n\n\n\n\n\n\n\n\n\n\n\n\nanova_result <- aov(Wage ~ educationLevel, data = merged_table)\n\n# Perform Tukey's post hoc test for pairwise comparisons\ntukey_result <- TukeyHSD(anova_result)\ntukey_result\ntukey_summary <- tidy(tukey_result)\n\nDT::datatable(head(tukey_summary, 20))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#average-joviality-vs.-interest-group",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#average-joviality-vs.-interest-group",
    "title": "Exploring City of Engagement’s household demographic and spending patterns",
    "section": "Average joviality vs. interest group",
    "text": "Average joviality vs. interest group\nTo understand which interest group that participants joined has the highest joviality, we used the average joviality of each interest group.\nObservation: Interest group E has the highest joviality compared to others, with an average 0.53 and Interest group H has the lowest joviality with an average 0.45.\n\nThe plotCode\n\n\n\n\n\n\n\n\n\n\nmerged_table_joviality <- merged_table %>%\n  select(participantId, interestGroup, joviality) %>%\n  group_by(interestGroup)                 \n\nmerged_table_joviality <- unique(merged_table_joviality)\n\nmerged_table_joviality <- merged_table_joviality %>%\n  group_by(interestGroup) %>%\n  mutate(average_joviality = mean(joviality)) %>%\n  select(interestGroup, average_joviality) %>%\n  distinct()\n\n\nggdotplotstats(data = merged_table_joviality,\n               y = interestGroup,\n               x = average_joviality,\n               type = \"robust\",\n               title = \"Average joviality by Interest Group\",\n               xlab = \"Joviality\",\n               ggtheme = theme_bw())"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#average-joviality-vs.-interest-group-vs.-age_group",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#average-joviality-vs.-interest-group-vs.-age_group",
    "title": "Exploring City of Engagement’s household demographic and spending patterns",
    "section": "Average joviality vs. interest group vs. age_group",
    "text": "Average joviality vs. interest group vs. age_group\nTo see whether interest group and joviality is affected by age_group\n\nThe plotCode\n\n\n\n\n\n\n\n\n\n\n\n merged_table_joviality_age_group <- merged_table %>%\n  select(participantId, age_group,joviality, interestGroup) %>%\n  group_by(interestGroup, age_group) %>%\n  mutate(average_joviality = mean(joviality))%>%\n  distinct() %>%\n  select(age_group, interestGroup, average_joviality)\n\ntooltip <- function(y, ymax, accuracy = .01) {   \n  mean <- scales::number(y, accuracy = accuracy) \n  sem <- scales::number(ymax - y, accuracy = accuracy) \n  paste(\"Mean joviality:\", mean, \"+/-\", sem) \n}\n\ngg_point <- ggplot(data=merged_table_joviality_age_group, \n                   aes(x = reorder(interestGroup,age_group)),\n) +\n  stat_summary(aes(y = average_joviality, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,\n    fill = \"lightblue\"\n    \n  ) +\n  stat_summary(aes(y = average_joviality),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  ) +\n  facet_wrap(~age_group)+\n  coord_flip()+\n  theme_bw() +\n  \n  theme(legend.position = \"none\") +\n  theme(panel.grid = element_blank()) +\n  labs(title = \"Average joviality by Interest group by age\", \n       y = \"Average Joviality\", \n       x = \"Interest Group\") \n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\nTo see whether interest group and joviality is affected by wage_group\n\nThe plotCode\n\n\n\n\n\n\n\n\n\n\n\nmerged_table_joviality_wage_group <- merged_table %>%\n  select(participantId, wage_group,joviality, interestGroup) %>%\n  group_by(interestGroup, wage_group) %>%\n  mutate(average_joviality = mean(joviality))%>%\n  distinct() %>%\n  select(wage_group, interestGroup, average_joviality)\n\ntooltip <- function(y, ymax, accuracy = .01) {   \n  mean <- scales::number(y, accuracy = accuracy) \n  sem <- scales::number(ymax - y, accuracy = accuracy) \n  paste(\"Mean joviality:\", mean, \"+/-\", sem) \n}\n\ngg_point <- ggplot(data=merged_table_joviality_wage_group, \n                   aes(x = reorder(interestGroup,wage_group)),\n) +\n  stat_summary(aes(y = average_joviality, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,\n    fill = \"lightblue\"\n    \n  ) +\n  stat_summary(aes(y = average_joviality),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  ) +\n  facet_wrap(~wage_group)+\n  coord_flip()+\n  theme_bw() +\n  \n  theme(legend.position = \"none\") +\n  theme(panel.grid = element_blank()) +\n  labs(title = \"Average joviality by Interest group by age\", \n       y = \"Average Joviality\", \n       x = \"Interest Group\") \n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\nInterest group I is dominated among 39-46 age group and super low wage group. Super Low income seems to enjoy the most and participate most in Interest group. However, for those super high income group, their source of happiness doesn’t come from interest group and they participate least in interest group."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#correlation-between-savings-and-joviality",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_v2.html#correlation-between-savings-and-joviality",
    "title": "Exploring City of Engagement’s household demographic and spending patterns",
    "section": "Correlation between savings and joviality",
    "text": "Correlation between savings and joviality\nDoes it mean the more you earn, the happier you are?\nLet’s find out from below correlation plot:\n\nThe plotCode\n\n\n\n\n\n\n\n\n\n\nggscatterstats(\n data = merged_table,\nx = Savings,\ny = joviality,\nmarginal = FALSE) +\n  \n  theme_minimal() +\n  \n  labs(title = 'Correlation of Joviality and Savings', x = \"Savings\", y = \"Joviality\") +\n\ntheme(\n        plot.title = element_text(hjust = 0.2, size = 15, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\")\n\n\n\n\nThere’s a negative relationship between joviality and savings. The more savings you have the less happy you are, which suggested that money cannot guarantee your happiness.\nTo have a closer look on which savings group have a higher joviality, we plot correlation between savings group. We break savings into 5 groups (super low, low, medium, high, super high) There is a strong negative correlation when people has a super low financial health.\n\nThe plotCode\n\n\n\n\n\n\n\n\n\n\np1 <- ggscatterstats(\n data = merged_table |>filter(savings_group == \"super low\"),\nx = Savings,\ny = joviality,\nmarginal = FALSE) +\n  \n  theme_minimal() +\n  \n  labs(x = \"Savings\", y = \"Joviality\") +\n\ntheme(\n        plot.title = element_text(hjust = 0.2, size = 15, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\")\n\np2 <- ggscatterstats(\n data = merged_table |>filter(savings_group == \"low\"),\nx = Savings,\ny = joviality,\nmarginal = FALSE) +\n  \n  theme_minimal() +\n  \n  labs(x = \"Savings\", y = \"Joviality\") +\n\ntheme(\n        plot.title = element_text(hjust = 0.2, size = 15, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\")\n\np3 <- ggscatterstats(\n data = merged_table |>filter(savings_group == \"medium\"),\nx = Savings,\ny = joviality,\nmarginal = FALSE) +\n  \n  theme_minimal() +\n  \n  labs(x = \"Savings\", y = \"Joviality\") +\n\ntheme(\n        plot.title = element_text(hjust = 0.2, size = 15, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\")\n\np4 <- ggscatterstats(\n data = merged_table |>filter(savings_group == \"high\"),\nx = Savings,\ny = joviality,\nmarginal = FALSE) +\n  \n  theme_minimal() +\n  \n  labs(x = \"Savings\", y = \"Joviality\") +\n\ntheme(plot.title = element_text(hjust = 0.2, size = 15, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\")\n\np5 <- ggscatterstats(\n data = merged_table |>filter(savings_group == \"super high\"),\nx = Savings,\ny = joviality,\nmarginal = FALSE) +\n  \n  theme_minimal() +\n  \n  labs(x = \"Savings\", y = \"Joviality\") +\n\ntheme(\n        plot.title = element_text(hjust = 0.2, size = 15, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\")\n\np1 + p2 + p3 + p4 + p5\n\n\n\n\nIt is interesting to note that individuals with super low income who exhibit remarkably highest average joviality scores of 0.75. Joviality exhibits a stronger negative correlation with lower income levels compared to wealthier individuals."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Identify companies that fit a pattern of illegal fishing",
    "section": "",
    "text": "pacman::p_load(jsonlite,tidygraph,ggraph, visNetwork, tidyverse, lubridate, plotly, DT, zoo, dplyr, ggplot2, tidyr)\n\n\n\n\n\nMC2 <- jsonlite::fromJSON(\"data/mc2_challenge_graph.json\")\n\n\n\n\n\n\n\n\nShow code\nmc2_nodes <- as_tibble(MC2$nodes)%>%\n  select(id, shpcountry, rcvcountry)\nDT::datatable(mc2_nodes, class = \"display\")\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nmc2_edges <- as_tibble(MC2$links) %>%\n  mutate(ArrivalDate = ymd(arrivaldate)) %>%\n  mutate(Year = year(ArrivalDate)) %>%\n  select(source, target, ArrivalDate, Year, hscode, valueofgoods_omu, \n         volumeteu, weightkg, valueofgoodsusd) %>% \n  distinct()\nDT::datatable(head(mc2_edges,20), class = \"display\")\n\n\n\n\n\n\n\n\n\n\nOur primary goal is to identify companies engaged in illegal fishing activities. In accordance with information from external sources, we need to focus on filtering out those companies with Harmonized System (HS) code prefixes ranging from 301 to 309.\n\n\nShow code\nmc2_edges_fishing <- mc2_edges %>%\n  filter(str_sub(hscode, 1, 3) %in% c(\"301\", \"302\", \"303\", \"304\", \"305\", \"306\", \"307\", \"308\", \"309\"))\n\n\n\n\n\nWe discovered that the columns “valueofgoodsusd” and “valueofgoods_omu” both contained missing values. Some rows, however, provided values in both of these columns. Utilizing this information, we were able to ascertain a conversion rate of 1.5384 (omu/usd). This conversion rate was subsequently employed to fill in the missing data in these columns.\n\n\nShow code\nconversion_rate <- 1.5384 \nmc2_edges_fishing$valueofgoodsusd <- ifelse(is.na(mc2_edges_fishing$valueofgoodsusd), \n                              round(mc2_edges_fishing$valueofgoods_omu / conversion_rate,0), \n                              mc2_edges_fishing$valueofgoodsusd)\nmc2_edges_fishing <- mc2_edges_fishing %>%\n  select(source, target, ArrivalDate, Year, hscode,volumeteu, weightkg, valueofgoodsusd)\n\n\n\n\n\nThe frequency of shipments for each unique pair of source and target, differentiated by their respective Harmonized System (HS) code and year. We aggregate edges, get the shipment counts and filter out those shipment counts greater than 20\n\n\nShow code\nmc2_edges_aggregated <- mc2_edges_fishing %>%\n  group_by(source, target, hscode, Year) %>%\n    summarise(weights = n()) %>%\n  filter(source!=target) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n\n\n\n\n\nTo identify companies potentially involved in illegal fishing activities, we adopted a two approaches focusing on their shipment frequency and any abnormal fluctuations in shipment value over the years. Companies that exhibited both these characteristics were considered suspicious and were consequently flagged as possible illegal fishing entities.\n\n\nillegal fishing company significantly increases or decreases its shipment frequency suddenly, it can be a sign that the company is trying to avoid detection, manipulate market prices, or respond to changes in enforcement intensity.\nApproach: calculate an average shipping frequency over a 2 year period and get a list of companies with sudden changes in their shipment volume over each time period compared to their threshold.\n\n\nShow code\nmc2_edges_aggregated <- mc2_edges_aggregated %>%\n  arrange(source, target, Year) %>%\n  group_by(source, target)\ndistinct_mc2_edges_aggregated <- mc2_edges_aggregated %>%\n  group_by(source, target) %>%\n  summarize(distinct_count = n()) %>%\n  ungroup() %>%\n  filter(distinct_count > 1)\n\nmc2_edges_aggregated <- inner_join(mc2_edges_aggregated, distinct_mc2_edges_aggregated, by = c(\"source\", \"target\"))\nfrequency_pct <- mc2_edges_aggregated %>%\n  group_by(source, target) %>%\n  arrange(Year) %>%\n  mutate(PercentageChange = weights / lag(weights) - 1)\n\nthreshold <- 0.5\nmc2_sudden_changes <- frequency_pct %>%\n  filter(abs(PercentageChange) > threshold)\n\ncompany_list_frequency <- unique(mc2_sudden_changes$source)\n\n\n\n\n\nillegal fishing might under-declare the weight of their catch to minimize attention and lower duties or taxes. On the other side, might over-declare the value of their shipment to over-insure it. These would lead to an abnormally high value-weight ratio.\nApproach: In order to detect irregularities in the declared value of goods, we analyze the shipment values and shipment weight ratios for each fishing entity. We establish a threshold value that captures the range within which 95% of the data in the value_weight_ratio_change variable falls. If the value_weight_ratio_change surpasses this threshold, we flag the corresponding fishing company as having an abnormal occurrence.\n\n\nShow code\nmc2_edges_fishing_stats <- mc2_edges_fishing %>%\n  arrange(source, target, Year) %>%\n  group_by(source, target) %>%\n  mutate(value_weight_ratio = valueofgoodsusd / weightkg) %>%\n  mutate(value_weight_ratio_change = value_weight_ratio / lag(value_weight_ratio) - 1)\n\nthreshold <- quantile(mc2_edges_fishing_stats$value_weight_ratio_change, 0.95, na.rm = TRUE) \n\nmc2_edges_fishing_abnormal <- mc2_edges_fishing_stats %>%\n  filter(abs(value_weight_ratio_change) > threshold)\ncompany_list <- unique(mc2_edges_fishing_abnormal$source)\n\n\n\n\n\n265 fishing entities violates both red flags\n\n\nShow code\nillegal_fishing_company <- intersect(company_list, company_list_frequency)\nillegal_fishing_company <- data.frame(Illegal_Fishing_Company = unlist(illegal_fishing_company))\ndatatable(illegal_fishing_company, options = list(pageLength = 5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nillegal_fishing_company <- intersect(company_list, company_list_frequency)\nillegal_fishing_company_aggregated_source <- mc2_edges_aggregated %>%\n  filter(source %in% illegal_fishing_company) \nillegal_fishing_company_aggregated_target <- mc2_edges_aggregated %>%\n  filter(target %in% illegal_fishing_company) \nillegal_fishing_company_aggregated <- rbind(illegal_fishing_company_aggregated_source, illegal_fishing_company_aggregated_target)\nillegal_fishing_company_aggregated <- illegal_fishing_company_aggregated %>%\n  select(source, target, hscode, Year, weights)\n\n\n\n\n\n\n\nShow code\nid1 <- illegal_fishing_company_aggregated$source\nid2 <- illegal_fishing_company_aggregated$target\nillegal_fishing_company_nodes_extracted <- c(id1, id2) \nillegal_fishing_company_nodes_extracted <- unique(illegal_fishing_company_nodes_extracted)\nillegal_fishing_company_nodes_extracted <- data.frame(illegal_fishing_company_nodes_extracted)\nillegal_fishing_company_nodes_extracted <- rename(illegal_fishing_company_nodes_extracted, id = illegal_fishing_company_nodes_extracted)\n\n\n\n\n\n\n\nShow code\nmc2_graph <- tbl_graph(nodes = illegal_fishing_company_nodes_extracted,\n                           edges = illegal_fishing_company_aggregated,\n                           directed = TRUE)\n\n\n\n\n\n\n\nShow code\nedges_df <- mc2_graph %>%\n  activate(edges) %>%\n  as_tibble()\n\n\n\n\n\n\n\nShow code\nnodes_df <- mc2_graph %>%\n  activate(nodes) %>%\n  as_tibble() %>%\n  rename(label = id) %>%\n  mutate(id=row_number()) %>%\n  select(id, label)\n\n\n\n\n\n\n\n\n\n\n\nShow code\nvisNetwork(nodes_df,\n           edges_df) %>%\n  visIgraphLayout(layout = \"layout_with_kk\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Visual analytics process to find similar businesses",
    "section": "",
    "text": "The objective of this challenge is to utilize the visual analytics process to identify and categorize the products and services offered by companies based on their similarity. To achieve this, we will utilize Topic modeling (LDA), to extract the main objectives from each group. Through this method, we can assign topics to business group based on their product_service description. Subsequently, we will proceed to cluster the companies together based on their similarities."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#load-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#load-packages",
    "title": "Visual analytics process to find similar businesses",
    "section": "Load packages",
    "text": "Load packages\n\npacman::p_load(jsonlite, tidygraph, ggraph, \n               visNetwork, graphlayouts, ggforce, \n               skimr, tidytext, tidyverse, SnowballC, hunspell, textstem, udpipe, dplyr, tm, text2vec, topicmodels, widyr, textmineR, topicdoc, fpc, cluster, ggplot2, scales, plotly, wordcloud, RColorBrewer, gridExtra, grid, forcats)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-edges",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-edges",
    "title": "Visual analytics process to find similar businesses",
    "section": "Extracting edges",
    "text": "Extracting edges\n\nmc3_edges <- as_tibble(MC3$links) %>% \n  distinct() %>%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %>%\n  group_by(source, target, type) %>%\n    summarise(weights = n()) %>%\n  filter(source!=target) %>%\n  ungroup()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-nodes",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-nodes",
    "title": "Visual analytics process to find similar businesses",
    "section": "Extracting nodes",
    "text": "Extracting nodes\n\nmc3_nodes <- as_tibble(MC3$nodes) %>%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %>%\n  select(id, country, type, revenue_omu, product_services)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation",
    "title": "Visual analytics process to find similar businesses",
    "section": "Data preparation",
    "text": "Data preparation\n\nStep 1. Address missing values replace character(0) with NA, and drop those NAs\n\n\nShow code\nmc3_nodes <- mc3_nodes %>%\n  mutate(product_services = ifelse(product_services == \"character(0)\", NA, product_services)) %>%\n  mutate(product_services = ifelse(product_services == \"Unknown\", NA, product_services))%>%\n  drop_na(product_services)\n\n\n\n\nStep 2: Tokenization and remove non-alphabets\n\n\nShow code\ntoken_nodes <- mc3_nodes %>%\n  unnest_tokens(word, \n                product_services)%>%\n\n  mutate(word = str_replace_all(word, \"[^a-z]\", \"\")) %>%\n  filter(word != \"\")\n\n\n\n\nStep 3: lemmatization\n\n\nShow code\ntoken_nodes$word <- lemmatize_words(token_nodes$word)\n\n\n\n\nStep 4: remove stopwords\n\n\nShow code\ndata(\"stop_words\")\ntoken_nodes <- token_nodes %>%\n  anti_join(stop_words)\n\n\n\n\nStep 5: remove words that are not in the dictionary\n\n\nShow code\ntoken_nodes <- token_nodes %>%\n  filter(hunspell_check(word))\n\n\n\n\nStep 6: keep only nouns\n\n\nShow code\nud_model <- udpipe_download_model(language = \"english\")\nud_model <- udpipe_load_model(ud_model$file_model)\n\ntoken_nodes_filter <- udpipe_annotate(ud_model, x = token_nodes$word)\ntoken_nodes_filter <- as.data.frame(token_nodes_filter)\ntoken_nodes_filter <- token_nodes_filter[token_nodes_filter$upos == \"NOUN\", ]\ntoken_nodes_filter <- token_nodes_filter %>% \n  select(lemma, upos) %>%\n  distinct(lemma, upos)\n\ntoken_nodes_table <- left_join(token_nodes, token_nodes_filter, by = c(\"word\" = \"lemma\")) %>%\n  drop_na(upos) %>%\n  select(id, country, type, revenue_omu, word)\n\n\n\n\nStep 7: adding custom into stopwords\n\ncustom_stop_words <- bind_rows(stop_words, tibble(word = c( \"product\", \"service\", \"system\", \"process\", \"offer\", \"range\", \"supply\", \"solution\", \"source\",\n\"freelance\", \"researcher\", \"management\", \"component\", \"manufacturing\", \"distribution\", \"tool\", \"care\",\n\"industry\", \"service\", \"raw\", \"specialty\", \"home\", \"item\", \"specialty\", \"activity\", \"control\", \"line\", \"production\", \"prepared\", \"development\", \"product\", \"include\", \"business\", \"commercial\", \"die\", \"application\", \"industry\", \"international\", \"preparation\", \"special\", \"based\", \"natural\",  \"building\", \"build\", \"personal\", \"type\",  \"appliance\",  \"variety\", \"head\", \"ingredient\", \"series\", \"smoke\", \"material\"), lexicon = c(\"en\")))\n\ntoken_nodes_table <- token_nodes_table %>%\n  anti_join(custom_stop_words)\n\n\n\nStep 8: Retain the words that have a frequency of more than 5.\n\n\nShow code\nword_counts <- token_nodes_table %>%\n  count(word, sort = TRUE)\n\n# Filter out words with count less than 5\nfiltered_table <- word_counts %>%\n  filter(n >= 5)\n\ntoken_nodes_table <- semi_join(token_nodes_table, filtered_table, by = \"word\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualise-the-unique-words-in-product-service-field",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualise-the-unique-words-in-product-service-field",
    "title": "Visual analytics process to find similar businesses",
    "section": "Visualise the unique words in product service field",
    "text": "Visualise the unique words in product service field\n\nThe plotThe Code\n\n\n\n\n\n\n\n\n\n\ntoken_nodes_table %>%\n  count(word, sort = TRUE) %>%\n  top_n(15) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#lda",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#lda",
    "title": "Visual analytics process to find similar businesses",
    "section": "LDA",
    "text": "LDA\n\nCreate a Document-Term Matrix (DTM):\n\n# group the product services keywords of the same company into a row\ntoken_nodes_table <- token_nodes_table %>%\n  group_by(id) %>%\n  summarise(product_services = paste(word, collapse = \" \"))\n\ncorpus <- Corpus(VectorSource(token_nodes_table$product_services))\nnodes_dtm <- DocumentTermMatrix(corpus, control = list(tolower = TRUE, removePunctuation = TRUE, stopwords = TRUE))\ndtm_matrix <- as.matrix(nodes_dtm)\n\n\n\nCompute Coherence Score\nDetermining the optimal number of topics based on the highest coherence score suggests that having 6 topics is ideal.\n\nk <- 15\nset.seed(1234)\nlda_model <- LDA(nodes_dtm, k, method=\"Gibbs\", control=list(iter = 500, verbose = 25))\n\nK = 15; V = 1019; M = 3642\nSampling 500 iterations!\nIteration 25 ...\nIteration 50 ...\nIteration 75 ...\nIteration 100 ...\nIteration 125 ...\nIteration 150 ...\nIteration 175 ...\nIteration 200 ...\nIteration 225 ...\nIteration 250 ...\nIteration 275 ...\nIteration 300 ...\nIteration 325 ...\nIteration 350 ...\nIteration 375 ...\nIteration 400 ...\nIteration 425 ...\nIteration 450 ...\nIteration 475 ...\nIteration 500 ...\nGibbs sampling completed!\n\ncoherence <- topic_coherence(lda_model, nodes_dtm, top_n_tokens = 10, smoothing_beta = 1)\nk_values <- 1:15\ncoherence_table <- data.frame(k = k_values, \"coherence score\" = coherence)\ncoherence_table\n\n    k coherence.score\n1   1      -100.22628\n2   2      -217.74938\n3   3       -84.48798\n4   4      -191.00726\n5   5      -198.63736\n6   6       -84.15613\n7   7      -226.50561\n8   8      -202.58051\n9   9      -131.86465\n10 10      -198.55230\n11 11      -192.52602\n12 12      -125.37263\n13 13      -195.44364\n14 14      -169.19899\n15 15      -175.96578\n\n\n\n\nBuild LDA for topic modelling\n\nK <- 6\nset.seed(1234)\n# compute the LDA model, inference via 1000 iterations of Gibbs sampling\ntopicModel <- LDA(nodes_dtm, K, method=\"Gibbs\", control=list(iter = 500, verbose = 25))\n\nK = 6; V = 1019; M = 3642\nSampling 500 iterations!\nIteration 25 ...\nIteration 50 ...\nIteration 75 ...\nIteration 100 ...\nIteration 125 ...\nIteration 150 ...\nIteration 175 ...\nIteration 200 ...\nIteration 225 ...\nIteration 250 ...\nIteration 275 ...\nIteration 300 ...\nIteration 325 ...\nIteration 350 ...\nIteration 375 ...\nIteration 400 ...\nIteration 425 ...\nIteration 450 ...\nIteration 475 ...\nIteration 500 ...\nGibbs sampling completed!"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#word-cloud",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#word-cloud",
    "title": "Visual analytics process to find similar businesses",
    "section": "Word Cloud",
    "text": "Word Cloud\nBelow are the word clouds for each topic, representing the most frequent and significant words within each topic.\nTopic 1 Keywords: machine, steel, cast, construction, power, metal, equipment Industry: Manufacturing of construction equipment, heavy machinery, metal fabrication Description: Companies may specialize in working with steel and casting, utilizing machinery and power for their operations.\nTopic 2 Keywords: seafood, cod, tuna, fish, shellfish, marine, crab, fillet, salmon, shrimp Industry: Seafood processing and distribution, fishery, seafood restaurants Description: Company most likely involved in the seafood industry, specifically dealing with shrimp, salmon, fillet, shellfish, marine products, crab, cod, seafood, fish, and tuna. They may be engaged in activities such as fishing, processing, and selling various types of seafood products.\nTopic 3 Keywords: freight, cargo, truck, storage, air, sea, transport, warehouse, container Industry: Freight transportation, logistics, warehousing, shipping Description: Companies may specializes in cargo handling and storage solutions, offering efficient air, sea, and truck transportation services. They provide reliable shipping and delivery options, including container logistics and warehouse management. Their expertise lies in facilitating the smooth movement of goods, ensuring timely and secure transportation throughout the supply chain.\nTopic 4 Keywords: shoe, apparel, bag, design, rubber, furniture, market, household, footwear, manufacture Industry: Fashion and apparel manufacturing, shoe production, design, retail Description: Companies may operate in the retail or consumer goods industry. “rubber” could indicate that the company uses or specializes in rubber-based materials or products. It appears that the company’s business revolves around the production or sale of consumer goods, particularly in the fashion and home furnishing sectors.\nTopic 5 Keywords: package, poultry, meat, grocery, film, fruit, food, sauce, vegetable Industry: Food packaging, poultry and meat processing, grocery retail Description: Companies involved in the production, packaging, and distribution of various food products.\nTopic 6 Keywords: textile, paper, water, finish, paint, glue, fiber, light, base, fabric Industry: Textile manufacturing, paper production, adhesive and glue manufacturing\n\nTopic 1Topic 2Topic 3Topic 4Topic 5Topic 6The Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterms <- topicModel@terms\nbeta <- topicModel@beta\n\n# Number of words to show for each topic\nn_words <- 10\n\n# Create a word cloud for each topic\nfor (k in 1:6) { \n  prob <- beta[k, ]\n  words <- terms[order(prob, decreasing = TRUE)][1:n_words]\n  prob <- prob[order(prob, decreasing = TRUE)][1:n_words]\n  prob <- prob / sum(prob)\n  df <- data.frame(word = words, freq = prob)\n  wc <- wordcloud(words = df$word, freq = df$freq, min.freq = 1,\n            max.words = n_words, scale=c(4, 0.3), random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, \"Dark2\"), main = paste(\"Topic\", k))\n  plot_list[[k]] <- wc\n}\ngrid_arrange <- grid.arrange(grobs = plot_list, nrow = 4, ncol = 3)\ngrid.draw(grid_arrange)\n\n\n\n\n\nAssign topic to each company\n\n\nShow code\ntopic_word_probs <- tidy(topicModel, matrix = \"beta\")\ntoken_topic_words <- token_nodes_table %>%\n  unnest_tokens(word, \n                product_services)\ncompany_topics <- left_join(token_topic_words, topic_word_probs, by = c(\"word\" = \"term\"))\ncompany_topics <- company_topics %>%\n  group_by(id) %>%\n  top_n(1, beta) %>%\n  ungroup() %>%\n  select(id, topic, beta) \ncompany_topics <- unique(company_topics)\ntoken_nodes_table$topic <- company_topics$topic\ntoken_nodes_table$TopicLabel <- ifelse(token_nodes_table$topic == 1, \"Manufacturing and Construction Equipment\", ifelse(token_nodes_table$topic == 2, \"Seafood Industry\", ifelse(token_nodes_table$topic == 3, \"Freight and Logistics Industry\", ifelse(token_nodes_table$topic == 4, \"Fashion and Apparel Industry\", ifelse(token_nodes_table$topic == 5, \"Food packaging and Grocery Industry\", \"Textile and Paper Industry\")))))\n\ntopic_map <- token_nodes_table %>%\n  select(id, TopicLabel)\nDT::datatable(topic_map)\n\n\n\n\n\n\n\n\n\nDistribution of companies in each topic\n\nThe plotThe Code\n\n\n\n\n\n\n\n\n\n\n\ntopic_counts <- table(token_nodes_table$TopicLabel)\ntopic_counts_df <- data.frame(topic = names(topic_counts), count = as.numeric(topic_counts)) %>%\n  mutate(topic = reorder(topic, count))\nbar_plot <- ggplot(topic_counts_df, aes(x = topic, y = count)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(y = \"Count\", title = \"Topic Distribution\") +\n  theme_minimal() +\n  coord_flip() +\n  xlab(NULL) \nggplotly(bar_plot)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#unveiling-industry-insights",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#unveiling-industry-insights",
    "title": "Visual analytics process to find similar businesses",
    "section": "Unveiling Industry Insights",
    "text": "Unveiling Industry Insights\n\nExploring Revenue Distribution Across Diverse Sectors\nObservation:\nIn our analysis of different industries, we examined the median revenue for each industry. The manufacturing and construction equipment industry stood out with the highest median revenue, reaching approximately 34,000 omu. This industry’s strong performance can be attributed to its focus on producing machinery, steel casting, and utilizing power for construction purposes.\nFollowing closely behind is the freight and logistics industry, which boasts a median revenue of 33,000 omu. This industry is involved in the transportation and storage of goods, both by air and sea. Its pivotal role in facilitating trade and commerce contributes to its solid revenue figures.\nNot far behind is the food packaging and grocery industry, with a median revenue of 32,000 omu. This sector specializes in packaging food products, ensuring their quality and preservation. It also includes the grocery segment, offering a wide range of food items to consumers.\nIn the fourth position is the textile and paper industry, with a median revenue of 28.6 thousand omu. This industry is involved in the production of textiles, paper products, and related materials. It plays a vital role in the manufacturing and supply chain of various consumer goods.\nOn the other end of the spectrum, we find the seafood industry with a median revenue of 27,000 omu. This industry focuses on the harvesting, processing, and distribution of seafood products, meeting the demand for fresh and high-quality seafood.\nLastly, we have the fashion and apparel industry, which also showcases a median revenue of 27,000 omu. This sector encompasses the design, manufacturing, and retail of clothing and accessories, catering to fashion-conscious consumers.\nThese findings shed light on the revenue distribution across different industries. It’s clear that the manufacturing and construction equipment industry leads the way, followed closely by freight and logistics, and food packaging and grocery.\n\nrevenue_business_group <- inner_join(topic_map, mc3_nodes, by = \"id\")\nrevenue_business_group <- revenue_business_group %>% \n  select(id, country, type, revenue_omu, TopicLabel) %>%\n  na.omit()\n\n##remove outliers for each topic label\nfences <- revenue_business_group %>%\n  group_by(TopicLabel) %>%\n  summarise(lower_fence = quantile(revenue_omu, 0.25) - 1.5 * IQR(revenue_omu),\n            upper_fence = quantile(revenue_omu, 0.75) + 1.5 * IQR(revenue_omu))\n\n# Remove outliers for each TopicLabel\nfiltered_revenue_business_group <- revenue_business_group %>%\n  left_join(fences, by = \"TopicLabel\") %>%\n  filter(revenue_omu >= lower_fence, revenue_omu <= upper_fence) %>%\n  select(id, country, type, revenue_omu, TopicLabel)\n\np <- ggplot(filtered_revenue_business_group, aes(x = reorder(TopicLabel, desc(revenue_omu)), y = revenue_omu, fill = TopicLabel)) +\n  geom_boxplot() +\n  labs(x = \"Topic Label\", y = \"Revenue\") +\n  theme_minimal() +\n  coord_cartesian(ylim = c(0, 300000)) \np <- p + theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5))\n\nggplotly(p)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#unveiling-industry-titans",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#unveiling-industry-titans",
    "title": "Visual analytics process to find similar businesses",
    "section": "Unveiling Industry Titans",
    "text": "Unveiling Industry Titans\n\nExploring Dominant Players Across Countries\nObservation:\nIn the fashion and apparel industry, Osterivaria emerges as a dominant force, contributing to 52.4% of the total revenue. This country’s fashion industry thrives, showcasing its strong market presence and capturing a significant share of the industry’s revenue.\nMoving on to the food packaging and grocery industry, Utoporiana takes the lead, accounting for a substantial 66% of the revenue. This country’s efficient packaging and grocery sector plays a pivotal role in meeting consumer demands and driving revenue growth.\nWhen it comes to the freight and logistics industry, Isliandor emerges as a major player, contributing to 43.2% of the total revenue. The country’s well-established logistics infrastructure and strategic location position it as a hub for transportation and storage, attracting significant business activity.\nIn the manufacturing and construction equipment industry, Alverovia stands out with a significant market share, accounting for 29.8% of the revenue. The country’s expertise in manufacturing and construction-related machinery and equipment contributes to its strong performance in this industry.\nThe seafood industry showcases a clear leader, with ZH dominating the market and accounting for a remarkable 72.25% of the revenue. This country’s abundant marine resources and expertise in seafood processing and distribution solidify its position as a key player in the global seafood market.\nFinally, in the textile and paper industry, ZH once again takes the spotlight, accounting for 35.9% of the total revenue. The country’s advanced textile manufacturing capabilities and robust paper production sector contribute to its significant revenue share.\nThese findings highlight the prominent role played by specific countries in each industry, showcasing their expertise, market dominance, and revenue contribution. Understanding the big players in various industries provides valuable insights into global market dynamics and helps identify potential areas for collaboration and investment.\n\nThe plotThe Code\n\n\n\n\n\n\n\n\n\n\n\ncluster_avg_revenue <- revenue_business_group %>%\n  group_by(TopicLabel,country) %>%\n  summarise(avg_revenue = mean(revenue_omu))\n# Plot the stacked bar plot\np <- ggplot(cluster_avg_revenue, aes(x = TopicLabel, y = avg_revenue, fill = country)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Cluster\", y = \"Average Revenue\") +\n  scale_fill_discrete(name = \"Country\") +\n  theme_minimal()+\n  theme(legend.position = \"bottom\", axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5))\n\n p <- p + scale_y_continuous(labels = comma)\n \n \nggplotly(p)"
  }
]